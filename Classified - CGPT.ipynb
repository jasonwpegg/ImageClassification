{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# just making sure Python is happy\n",
    "print(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import backend as k\n",
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# set hyperprameters and top-level variables\n",
    "data_dir = 'data3'\n",
    "log_dir = 'logs'\n",
    "model_dir = 'models'\n",
    "best_weights = os.path.join(model_dir,'weights.best.hdf5')\n",
    "\n",
    "imgsize = 750\n",
    "batchsize = 32\n",
    "epochs = 32\n",
    "learning_rate = 0.001           # default 0.001\n",
    "epsilon = 1e-07                 # default 1e-07\n",
    "dropout_rate = 0.25"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# function to determine rough model memory requirements\n",
    "def get_model_memory_usage(batch_size, model_to_review):\n",
    "    shapes_mem_count = 0\n",
    "    internal_model_mem_count = 0\n",
    "    for l in model_to_review.layers:\n",
    "        layer_type = l.__class__.__name__\n",
    "        if layer_type == 'Model':\n",
    "            internal_model_mem_count += get_model_memory_usage(batch_size, l)\n",
    "        single_layer_mem = 1\n",
    "        out_shape = l.output_shape\n",
    "        if type(out_shape) is list:\n",
    "            out_shape = out_shape[0]\n",
    "        for s in out_shape:\n",
    "            if s is None:\n",
    "                continue\n",
    "            single_layer_mem *= s\n",
    "        shapes_mem_count += single_layer_mem\n",
    "\n",
    "    trainable_count = np.sum([k.count_params(p) for p in model_to_review.trainable_weights])\n",
    "    non_trainable_count = np.sum([k.count_params(p) for p in model_to_review.non_trainable_weights])\n",
    "\n",
    "    number_size = 4.0\n",
    "    if k.floatx() == 'float16':\n",
    "        number_size = 2.0\n",
    "    if k.floatx() == 'float64':\n",
    "        number_size = 8.0\n",
    "\n",
    "    total_memory = number_size * (batch_size * shapes_mem_count + trainable_count + non_trainable_count)\n",
    "    gbytes = np.round(total_memory / (1024.0 ** 3), 3) + internal_model_mem_count\n",
    "    return gbytes"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Hide the GPU - forces CPU training\n",
    "# tf.config.set_visible_devices([], 'GPU')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "   tf.config.experimental.set_memory_growth(gpu, True)\n",
    "   #tf.config.experimental.set_virtual_device_configuration(gpu, [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=8192)])\n",
    "tf.config.list_physical_devices('GPU')"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Load, Scale, and Review Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load and scale the data\n",
    "data = tf.keras.utils.image_dataset_from_directory(data_dir, batch_size=batchsize, image_size=(imgsize, imgsize))\n",
    "data = data.map(lambda x,y: (x/255, y))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# review the data parameters\n",
    "data_iterator = data.as_numpy_iterator()\n",
    "batch = data_iterator.next()\n",
    "print(batch[0][0])\n",
    "print(batch[1])\n",
    "print(batch[0].shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# review the data as images\n",
    "fig, ax = plt.subplots(ncols=5, figsize=(20, 20))\n",
    "for idx, img in enumerate(batch[0][:5]):\n",
    "    ax[idx].imshow(img.astype(int))\n",
    "    # ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(batch[1][idx])"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Split Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_size = int(len(data)*.7)\n",
    "val_size = int(len(data)*.2)\n",
    "test_size = int(len(data)*.1)\n",
    "print(\"Data size: \", len(data))\n",
    "print(\"Train size: \", train_size)\n",
    "print(\"Val size: \", val_size)\n",
    "print(\"Test size: \", test_size)\n",
    "print(\"Total size: \", train_size+val_size+test_size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Build Deep Learning Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# convolution layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(imgsize,imgsize,3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# dense layers with dropout\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(dropout_rate))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(dropout_rate))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up an optimizer and compile\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=epsilon)\n",
    "model.compile(optimizer=optimizer, loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "tensor_board = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "checkpoint = ModelCheckpoint(best_weights, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', verbose=1, patience=5, restore_best_weights=True)\n",
    "callbacks_list = [tensor_board, checkpoint, early_stopping]"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# how much memory might we need - limit around 6GB???\n",
    "get_model_memory_usage(batchsize, model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# summarize the model\n",
    "model.summary()"
   ],
   "metadata": {
    "tags": []
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=epochs, validation_data=val, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# plot loss\n",
    "f, ax = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(7, 9))\n",
    "ax[0].plot([None] + hist.history['loss'], 'o-')\n",
    "ax[0].plot([None] + hist.history['val_loss'], 'x-')\n",
    "ax[0].legend(['Train loss', 'Validation loss'], loc = 0)\n",
    "ax[0].set_title('Training/Validation Loss per Epoch')\n",
    "ax[0].set_ylabel('Loss')\n",
    "\n",
    "ax[1].plot([None] + hist.history['accuracy'], 'o-')\n",
    "ax[1].plot([None] + hist.history['val_accuracy'], 'x-')\n",
    "ax[1].legend(['Train Accuracy', 'Validation Accuracy'], loc = 0)\n",
    "ax[1].set_title('Training/Validation Accuracy per Epoch')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Accuracy')"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator(): \n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    pre.update_state(y, yhat)\n",
    "    re.update_state(y, yhat)\n",
    "    acc.update_state(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------------------------------------------\")\n",
    "print(\"Precision:       \", pre.result())\n",
    "print(\"Recall:          \", re.result())\n",
    "print(\"Binary Accuracy: \", acc.result())\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Validate and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img01 = cv2.imread(data_dir + '/_000/_0-01.jpg')\n",
    "img02 = cv2.imread(data_dir + '/_000/_0-02.jpg')\n",
    "img03 = cv2.imread(data_dir + '/_000/_0-03.jpg')\n",
    "img04 = cv2.imread(data_dir + '/_000/_0-04.jpg')\n",
    "img05 = cv2.imread(data_dir + '/_000/_0-05.jpg')\n",
    "\n",
    "img11 = cv2.imread(data_dir + '/_FAPT/_F-01.jpg')\n",
    "img12 = cv2.imread(data_dir + '/_FAPT/_F-02.jpg')\n",
    "img13 = cv2.imread(data_dir + '/_FAPT/_F-03.jpg')\n",
    "img14 = cv2.imread(data_dir + '/_FAPT/_F-04.jpg')\n",
    "img15 = cv2.imread(data_dir + '/_FAPT/_F-05.jpg')\n",
    "\n",
    "imgT01 = cv2.imread('test/_T-01.jpg')\n",
    "imgT02 = cv2.imread('test/_T-02.jpg')\n",
    "imgT13 = cv2.imread('test/_T-03.jpg')\n",
    "imgT14 = cv2.imread('test/_T-04.jpg')\n",
    "imgT15 = cv2.imread('test/_T-05.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(img01.shape)\n",
    "# plt.imshow(cv2.cvtColor(img01, cv2.COLOR_BGR2RGB))\n",
    "# plt.show()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resize01 = tf.image.resize(img01, (imgsize,imgsize))\n",
    "resize02 = tf.image.resize(img02, (imgsize,imgsize))\n",
    "resize03 = tf.image.resize(img03, (imgsize,imgsize))\n",
    "resize04 = tf.image.resize(img04, (imgsize,imgsize))\n",
    "resize05 = tf.image.resize(img05, (imgsize,imgsize))\n",
    "\n",
    "resize11 = tf.image.resize(img11, (imgsize,imgsize))\n",
    "resize12 = tf.image.resize(img12, (imgsize,imgsize))\n",
    "resize13 = tf.image.resize(img13, (imgsize,imgsize))\n",
    "resize14 = tf.image.resize(img14, (imgsize,imgsize))\n",
    "resize15 = tf.image.resize(img15, (imgsize,imgsize))\n",
    "\n",
    "resizeT01 = tf.image.resize(imgT01, (imgsize,imgsize))\n",
    "resizeT02 = tf.image.resize(imgT02, (imgsize,imgsize))\n",
    "resizeT13 = tf.image.resize(imgT13, (imgsize,imgsize))\n",
    "resizeT14 = tf.image.resize(imgT14, (imgsize,imgsize))\n",
    "resizeT15 = tf.image.resize(imgT15, (imgsize,imgsize))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(resize01.shape)\n",
    "# plt.imshow(cv2.cvtColor(resize01.numpy().astype(np.uint16), cv2.COLOR_BGR2RGB))\n",
    "# plt.show()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat01 = model.predict(np.expand_dims(resize01/255, 0))[0][0]\n",
    "yhat02 = model.predict(np.expand_dims(resize02/255, 0))[0][0]\n",
    "yhat03 = model.predict(np.expand_dims(resize03/255, 0))[0][0]\n",
    "yhat04 = model.predict(np.expand_dims(resize04/255, 0))[0][0]\n",
    "yhat05 = model.predict(np.expand_dims(resize05/255, 0))[0][0]\n",
    "\n",
    "yhat11 = model.predict(np.expand_dims(resize11/255, 0))[0][0]\n",
    "yhat12 = model.predict(np.expand_dims(resize12/255, 0))[0][0]\n",
    "yhat13 = model.predict(np.expand_dims(resize13/255, 0))[0][0]\n",
    "yhat14 = model.predict(np.expand_dims(resize14/255, 0))[0][0]\n",
    "yhat15 = model.predict(np.expand_dims(resize15/255, 0))[0][0]\n",
    "\n",
    "yhatT01 = model.predict(np.expand_dims(resizeT01/255, 0))[0][0]\n",
    "yhatT02 = model.predict(np.expand_dims(resizeT02/255, 0))[0][0]\n",
    "yhatT13 = model.predict(np.expand_dims(resizeT13/255, 0))[0][0]\n",
    "yhatT14 = model.predict(np.expand_dims(resizeT14/255, 0))[0][0]\n",
    "yhatT15 = model.predict(np.expand_dims(resizeT15/255, 0))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"{:.11f}\".format(yhat01), \" - Verify 0.0\")\n",
    "print(\"{:.11f}\".format(yhat02), \" - Verify 0.0\")\n",
    "print(\"{:.11f}\".format(yhat03), \" - Verify 0.0\")\n",
    "print(\"{:.11f}\".format(yhat04), \" - Verify 0.0\")\n",
    "print(\"{:.11f}\".format(yhat05), \" - Verify 0.0\")\n",
    "print(\"------------------------\")\n",
    "print(\"{:.11f}\".format(yhat11), \" - Verify 1.0\")\n",
    "print(\"{:.11f}\".format(yhat12), \" - Verify 1.0\")\n",
    "print(\"{:.11f}\".format(yhat13), \" - Verify 1.0\")\n",
    "print(\"{:.11f}\".format(yhat14), \" - Verify 1.0\")\n",
    "print(\"{:.11f}\".format(yhat15), \" - Verify 1.0\")\n",
    "print(\"------------------------\")\n",
    "print(\"{:.11f}\".format(yhatT01), \" - Want 0.0\")\n",
    "print(\"{:.11f}\".format(yhatT02), \" - Want 0.0\")\n",
    "print(\"{:.11f}\".format(yhatT13), \" - Want 1.0\")\n",
    "print(\"{:.11f}\".format(yhatT14), \" - Want 1.0\")\n",
    "print(\"{:.11f}\".format(yhatT15), \" - Want 1.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.save(os.path.join('models','imageclassifier.h5'))\n",
    "# new_model = load_model(os.path.join('models', 'imageclassifier.h5'))\n",
    "# yhatnew = new_model.predict(np.expand_dims(resize01/255, 0))\n",
    "# print(yhatnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 10. Release Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# k.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cuda.select_device(0)\n",
    "# cuda.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
